{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0441eed9",
   "metadata": {},
   "source": [
    "<big>\n",
    "<h1>Submitted By - Ishan Ojha \n",
    "Assignment no 2 \n",
    "Cs-21 </h1></big>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6caa66b-45a3-4c46-9ac7-59387a20659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "#Installing tensor flow 2.19.0 @latest  not 1.13.1 because TensorFlow 1.13.1 is no longer available on the latest versions of Python and pip.\n",
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello TensorFlow!\")\n",
    "print(hello.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538bb4c",
   "metadata": {},
   "source": [
    "<h2>add operation and multiply operation and  understanding graph  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa79c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "x = 2\n",
    "y = 3\n",
    "z = tf.add(x, y, name='Add')\n",
    "print(z)\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    z = tf.add(x, y, name='Add')\n",
    "a = tf.multiply(3,3)\n",
    "print(a)\n",
    "a = tf.multiply(3, 3)  \n",
    "print(a.numpy()) \n",
    "x = tf.constant(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329a5e2",
   "metadata": {},
   "source": [
    "<h2>Math operations in TensorFlow </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d58142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "x = tf.constant([1., 2., 3.])\n",
    "y = tf.constant([3., 2., 1.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdfda2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding two numbers:\n",
    "sum = tf.add(x,y)\n",
    "sum.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f58011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  0.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtracting two numbers\n",
    "difference = tf.subtract(x,y)\n",
    "difference.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b69b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 3.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplying two numbers \n",
    "product = tf.multiply(x,y)\n",
    "product.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb13906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333334, 1.        , 3.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividing two numbres\n",
    "division = tf.divide(x,y)\n",
    "division.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a53379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dot product of x and y \n",
    "dot_product = tf.reduce_sum(tf.multiply(x, y))\n",
    "dot_product.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f10be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index of min and max elements \n",
    "x = tf.constant([10, 0, 13, 9])\n",
    "tf.argmin(x).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e39b8f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(x).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8b17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "#squared difference finding \n",
    "x = tf.Variable([1,3,5,7,11])\n",
    "y = tf.Variable([1])\n",
    "tf.math.squared_difference(x,y).numpy()\n",
    "#typecasting\n",
    "print (x.dtype)\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "print (x.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66be6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[3,6,9], [7,7,7]]\n",
    "y = [[4,5,6], [5,5,5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b231c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 6, 9],\n",
       "       [7, 7, 7],\n",
       "       [4, 5, 6],\n",
       "       [5, 5, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenation of two matrices row wise and col wise \n",
    "tf.concat([x, y], 0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a185ad84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 6, 9, 4, 5, 6],\n",
       "       [7, 7, 7, 5, 5, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([x, y], 1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85b852b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 7],\n",
       "       [6, 7],\n",
       "       [9, 7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking the matrix using the stack funciton \n",
    "tf.stack(x, axis=1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed46755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [2., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([[1.0, 5.0], [2.0, 3.0]])\n",
    "x.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a394b2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing the reduce mean operation \n",
    "tf.reduce_mean(input_tensor=x).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a597d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 4. ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=x, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0731751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3. ],\n",
       "       [2.5]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=x, axis=1, keepdims=True).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc36ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23677158, 0.98215866],\n",
       "       [0.23439384, 0.03067482],\n",
       "       [0.23570013, 0.63890517]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drawing random values from the probability distributions:\n",
    "tf.random.normal(shape=(3,2), mean=10.0, stddev=2.0).numpy()\n",
    "tf.random.uniform(shape = (3,2), minval=0, maxval=None, dtype=tf.float32,).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6b682ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8756006 , 0.00589975, 0.11849965], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax probabilities \n",
    "x = tf.constant([7., 2., 5.])\n",
    "tf.nn.softmax(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af09bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(x, x)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    print(square(6.).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cef0b1",
   "metadata": {},
   "source": [
    " <h2>TensorFlow 2.0 and Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cadf97",
   "metadata": {},
   "source": [
    "Building Compiling training and evaluating a model in keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20691395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "# Generating some sample data set\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, 7)   # 100 samples, 7 features\n",
    "labels = np.random.randint(0, 2, 100)  # Binary classification (0 or 1)\n",
    "\n",
    "data_test = np.random.rand(20, 7)  # 20 test samples\n",
    "labels_test = np.random.randint(0, 2, 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a396e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitro\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5163 - loss: 0.7059  \n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5969 - loss: 0.6927 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5349 - loss: 0.6936 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.6921 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5720 - loss: 0.6912 \n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5123 - loss: 0.6950 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4985 - loss: 0.6944 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4683 - loss: 0.6980 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4807 - loss: 0.7001 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5254 - loss: 0.6970 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5505 - loss: 0.6918 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5500 - loss: 0.6825\n",
      "Training Accuracy: 0.5300, Training Loss: 0.6944\n",
      "Test Accuracy: 0.5500, Test Loss: 0.6825\n"
     ]
    }
   ],
   "source": [
    "# 1. Defining the Model (Sequential API)\n",
    "model_seq = Sequential()\n",
    "model_seq.add(Dense(13, input_dim=7, activation='relu'))\n",
    "model_seq.add(Dense(7, activation='relu'))\n",
    "model_seq.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 2. Compiling the Model\n",
    "model_seq.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 3. Training the Model\n",
    "model_seq.fit(x=data, y=labels, epochs=10, batch_size=10)\n",
    "\n",
    "#4. Evaluating the Model\n",
    "train_loss, train_acc = model_seq.evaluate(x=data, y=labels)\n",
    "test_loss, test_acc = model_seq.evaluate(x=data_test, y=labels_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.4f}, Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43c981f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5514 - loss: 0.6812  \n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5862 - loss: 0.6699 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5017 - loss: 0.6927 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6831 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5661 - loss: 0.6842 \n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5260 - loss: 0.6904 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5660 - loss: 0.6654 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4505 - loss: 0.7016 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4872 - loss: 0.6973 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.6792 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5401 - loss: 0.6766 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4000 - loss: 0.7325\n",
      "[Functional] Training Accuracy: 0.5300, Training Loss: 0.6852\n",
      "[Functional] Test Accuracy: 0.4000, Test Loss: 0.7325\n"
     ]
    }
   ],
   "source": [
    "# Functional API Model \n",
    "# Define input layer\n",
    "input_layer = Input(shape=(7,))\n",
    "\n",
    "# Define hidden layers\n",
    "layer1 = Dense(13, activation='relu')(input_layer)\n",
    "layer2 = Dense(7, activation='relu')(layer1)\n",
    "\n",
    "# Define output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(layer2)\n",
    "\n",
    "# Create the model\n",
    "model_func = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the functional model\n",
    "model_func.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Train the functional model\n",
    "model_func.fit(x=data, y=labels, epochs=10, batch_size=10)\n",
    "\n",
    "# Evaluate the functional model\n",
    "train_loss, train_acc = model_func.evaluate(x=data, y=labels)\n",
    "test_loss, test_acc = model_func.evaluate(x=data_test, y=labels_test)\n",
    "\n",
    "print(f\"[Functional] Training Accuracy: {train_acc:.4f}, Training Loss: {train_loss:.4f}\")\n",
    "print(f\"[Functional] Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498988d",
   "metadata": {},
   "source": [
    "<h2>MNIST digit classification using\n",
    "TensorFlow 2.0</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2985075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff45dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "mnist =  tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ccbd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a train and test set:\n",
    "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalizing the x values by diving with maximum value of x which is 255 and convert them to float:\n",
    "x_train, x_test = tf.cast(x_train/255.0, tf.float32), tf.cast(x_test/255.0, tf.float32)\n",
    "# converting y values to int:\n",
    "y_train, y_test = tf.cast(y_train,tf.int64),tf.cast(y_test,tf.int64)\n",
    "# Defining the sequential model:\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee3951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the layers. applying ReLU activation at the first two layers \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "#applying softmax function in the final layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc5a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7349 - loss: 0.9835\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2942\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9338 - loss: 0.2326\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1974\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1765\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.1543\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1331\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1251\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9693 - loss: 0.1113\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.1085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21047466b70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model with Stochastic Gradient Descent, that is 'sgd' \n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model for 10 epochs with batch_size as 32:\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2bfda59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9608 - loss: 0.1312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1113937497138977, 0.9670000076293945]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the model on test sets\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
